# codigo mejorado según la versión de DATABRICKS
# ORIGINAL EN COLAB 
# -*- coding: utf-8 -*-
"""Copia de 20240310 allinone.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1c-CLyrsu9ZKNd2EXWUXTrJU0JzJrkOai
"""

import pandas as pd
import numpy as np
from xgboost import XGBRegressor
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split
import time
import plotly.graph_objects as go
import pickle

# Cargar los datos de entrenamiento del modelo
data = pd.read_csv('E:/2024/databricks/notebook 25032024/XGBoost py/API/allinone20240228.csv', sep=';', quotechar='"')

# Mostrar las primeras filas del DataFrame para inspeccionar los datos
print(data.head())


# Imprimir los nombres de las columnas para una verificación automática
print(data.columns)


# Convertir la columna de fechas a formato datetime si no se hizo automáticamente
data['tm'] = pd.to_datetime(data['tm'])

# Establecer la columna de fechas como el índice del DataFrame
data.set_index('tm', inplace=True)

# Ingeniería de características: Crear lags de temperatura como nuevas características
# NUEVA modificación con toda la serie de datos y que funciona en la API
temp_series = data['temp']
temp_df = pd.DataFrame(temp_series)

for lag in range(1, 25):  # Crear lags de 1 a 24 horas
    temp_df[f'lag_{lag}'] = temp_df['temp'].shift(lag)

# Eliminar las filas con valores NaN resultantes de la creación de lags
temp_df_cleaned = temp_df.dropna()

# Separar las características y la variable objetivo
X = temp_df_cleaned.drop('temp', axis=1)
y = temp_df_cleaned['temp']

# Calcula el índice para la división basado en la proporción deseada
# Nota: Asegúrate de que X y y estén ordenados temporalmente si estás trabajando con series temporales
dividir_en = int(len(X) * 0.2)  # 20% para entrenamiento, 80% para prueba

# Divide los datos manualmente basado en el índice calculado
X_train = X.iloc[:dividir_en]
y_train = y.iloc[:dividir_en]
X_test = X.iloc[dividir_en:]
y_test = y.iloc[dividir_en:]

# Separamos train_size de 0.8 y un test_size de 0.2 dividirán los datos en 80% para entrenamiento y 20% para prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.2, test_size=0.8, random_state=42)


# Definimos el modelo XGBoost 09-04
xgb_model = XGBRegressor(n_estimators=100, learning_rate=0.1, objective='reg:squarederror')
#xgb_model.fit(X, y) #xgb_model.fit(X_train, y_train)20240324

# Entrenar el modelo XGBoost solo con los datos de entrenamiento 09-04
xgb_model.fit(X_train, y_train)

# Guardar el modelo entrenado VERSION 08-05
#model_path = 'E:\\2024\\databricks\\notebook 25032024\\XGBoost py\\XGBoost0805v1.model'
# xgb_model.save_model(model_path)

# Guardar el modelo entrenado como un archivo .pkl hacemos la persistencia del modelo, con esto lo volvemos a usar 
with open('modelo_entrenado1305.pkl', 'wb') as file:
    pickle.dump(xgb_model, file)

# Realizar predicciones en el conjunto de prueba allinone20240228
y_pred_xgb = xgb_model.predict(X_test)

# Calcular RMSE solo para las predicciones del conjunto de prueba  allinone20240228
rmse_xgb = np.sqrt(mean_squared_error(y_test, y_pred_xgb))
print(f"RMSE: {rmse_xgb}")


# Gráfico de valores reales
fig_real = go.Figure()
fig_real.add_trace(go.Scatter(x=data.index, y=data['temp'], mode='lines+markers', name='Real'))
fig_real.update_layout(title='Temperatura Real', xaxis_title='Fecha y Hora', yaxis_title='Temperatura (°C)', hovermode="x")
fig_real.show()

# Gráfico de valores predichos
fig_pred = go.Figure()
fig_pred.add_trace(go.Scatter(x=data.index, y=y_pred_xgb, mode='lines+markers', name='Predicho', marker_color='rgba(255, 0, 0, 0.5)'))
fig_pred.update_layout(title='Temperatura Predicha', xaxis_title='Fecha y Hora', yaxis_title='Temperatura (°C)', hovermode="x")
fig_pred.show()

"""El RMSE te dice cuánto se desvían en promedio las predicciones del modelo de los valores reales.
El resultado del modelo de predicción nos indica que la variable temepratura predicha tiene un error de 0,612 ºC, en nuestro análisis son décimas de temperatura que no afectarían tanto a la aplicacion
"""

# Aplicar suavizado por promedio móvil
window_size = 8  # Define el tamaño de la ventana para el promedio móvil, cuanto mas grande mas suave la curva

# Suavizar los valores reales
data_smoothed = data['temp'].rolling(window=window_size).mean()

# Suavizar las predicciones
y_pred_xgb_smoothed = pd.Series(y_pred_xgb).rolling(window=window_size).mean()

# Gráfico de valores reales suavizados
fig_real_smoothed = go.Figure()
fig_real_smoothed.add_trace(go.Scatter(x=data.index[window_size - 1:], y=data_smoothed[window_size - 1:], mode='lines', name='Real Suavizado'))
fig_real_smoothed.update_layout(title='Temperatura Real Suavizada', xaxis_title='Fecha y Hora', yaxis_title='Temperatura (°C)', hovermode="x")
fig_real_smoothed.show()

# Gráfico de valores predichos suavizados
fig_pred_smoothed = go.Figure()
fig_pred_smoothed.add_trace(go.Scatter(x=data.index[window_size - 1:], y=y_pred_xgb_smoothed[window_size - 1:], mode='lines', name='Predicho Suavizado', marker_color='rgba(255, 0, 0, 0.5)'))
fig_pred_smoothed.update_layout(title='Temperatura Predicha Suavizada', xaxis_title='Fecha y Hora', yaxis_title='Temperatura (°C)', hovermode="x")
fig_pred_smoothed.show()

#Código para nuevos datos
import pandas as pd
from sqlalchemy import create_engine
from xgboost import XGBRegressor

#instalacion para mysql
import subprocess
import sys

# Comando para instalar pymysql
command = [sys.executable, "-m", "pip", "install", "pymysql"]

# Ejecutar el comando
subprocess.run(command, shell=True)

# Cambia la URL por la ruta a tu archivo de dato
#url = 'g:/DI-LYTICS/notebooks/xgboost/allinone20240505.csv'
#data_nuevo = pd.read_csv(url, sep=';', quotechar='"')

#Conexion a MYSQL
usuario = 'wi200391_kika'
contraseña = 'Kika2008'
nombre_base_de_datos = 'wi200391_dataiot'
host = '200.58.107.20'  # Por ejemplo, 'localhost'
puerto = '3306'  

# Cadena de conexión para MySQL
cadena_conexion = f"mysql+pymysql://{usuario}:{contraseña}@{host}:{puerto}/{nombre_base_de_datos}"

# Crear la conexión a la base de datos
engine = create_engine(cadena_conexion)

# Consulta SQL para extraer la tabla deseada
consulta_sql = "SELECT * FROM datos"  # Reemplaza por el nombre real de tu tabla

# Ejecutar la consulta y cargar los resultados en un DataFrame
data_nuevo = pd.read_sql_query(consulta_sql, engine)


print(data_nuevo.head(10))



# Asegúrate de que el nombre de la columna de fechas en tu archivo coincide con 'tm' y ajusta según sea necesario
# Convertir la columna de fechas a formato datetime si no se hizo automáticamente
data_nuevo['tm'] = pd.to_datetime(data_nuevo['tm'])

# Establecer la columna de fechas como el índice del DataFrame
data_nuevo.set_index('tm', inplace=True)

# Suponiendo que 'data_nuevo' es tu nuevo DataFrame y ya está definido

# Importar las bibliotecas necesarias
from xgboost import XGBRegressor
from sklearn.metrics import mean_squared_error
import numpy as np
import plotly.graph_objects as go

# Ingeniería de características: Crear lags de temperatura como nuevas características
temp_series_nuevo = data_nuevo['temp']  # Asegúrate de que 'temp' es el nombre correcto de la columna
temp_df_nuevo = pd.DataFrame(temp_series_nuevo)

for lag in range(1, 25):  # Crear lags de 1 a 24 horas
    temp_df_nuevo[f'lag_{lag}'] = temp_df_nuevo['temp'].shift(lag)

temp_df_cleaned_nuevo = temp_df_nuevo.dropna()

X_nuevo = temp_df_cleaned_nuevo.drop('temp', axis=1)
y_nuevo = temp_df_cleaned_nuevo['temp']

# Entrenar el modelo XGBoost
xgb_model_nuevo = XGBRegressor(n_estimators=100, learning_rate=0.1, objective='reg:squarederror')
xgb_model_nuevo.fit(X_nuevo, y_nuevo)

y_pred_xgb_nuevo = xgb_model_nuevo.predict(X_nuevo)

# Calcular RMSE para las predicciones
rmse_xgb_nuevo = np.sqrt(mean_squared_error(y_nuevo, y_pred_xgb_nuevo))
print(f"RMSE: {rmse_xgb_nuevo}")

# Añadir las visualizaciones aquí, ajustando 'data_nuevo.index' y 'data_nuevo['temp']'
# según la estructura de tu nuevo DataFrame

# Gráfico de valores reales
fig_real = go.Figure()
fig_real.add_trace(go.Scatter(x=data_nuevo.index, y=data_nuevo['temp'], mode='lines+markers', name='Real'))
fig_real.update_layout(title='Temperatura Real', xaxis_title='Fecha y Hora', yaxis_title='Temperatura (°C)', hovermode="x")
fig_real.show()

# Gráfico de valores predichos
fig_pred = go.Figure()
fig_pred.add_trace(go.Scatter(x=data_nuevo.index, y=y_pred_xgb_nuevo, mode='lines+markers', name='Predicho', marker_color='rgba(255, 0, 0, 0.5)'))
fig_pred.update_layout(title='Temperatura Predicha', xaxis_title='Fecha y Hora', yaxis_title='Temperatura (°C)', hovermode="x")
fig_pred.show()

#Gráficas suavizadas
from scipy.ndimage import gaussian_filter1d

# Aplicar suavizado exponencial a las predicciones
y_pred_xgb_smoothed = gaussian_filter1d(y_pred_xgb_nuevo, sigma=2)

# Gráfico de valores predichos suavizados
fig_pred_smoothed = go.Figure()
fig_pred_smoothed.add_trace(go.Scatter(x=data_nuevo.index[window_size - 1:], y=y_pred_xgb_smoothed[window_size - 1:], mode='lines', name='Predicho Suavizado', marker_color='rgba(255, 0, 0, 0.5)'))
fig_pred_smoothed.update_layout(title='Temperatura Predicha Suavizada', xaxis_title='Fecha y Hora', yaxis_title='Temperatura (°C)', hovermode="x")
fig_pred_smoothed.show()

# grafico en conjunto
import plotly.graph_objects as go
from plotly.subplots import make_subplots

# Calcular las diferencias entre los valores reales y predichos suavizados
# Asegurarnos de que los índices coincidan antes de realizar la resta
import plotly.graph_objects as go
from plotly.subplots import make_subplots

import plotly.graph_objects as go

# Crear un DataFrame con las fechas para las predicciones
fecha_inicio = data_nuevo.index[-1]  # Última fecha en el conjunto de datos original
fecha_fin = fecha_inicio + pd.DateOffset(hours=len(y_pred_xgb_nuevo))  # Asumiendo que cada predicción es una hora después de la anterior
fechas_prediccion = pd.date_range(start=fecha_inicio, end=fecha_fin, freq='H')

# Crear el gráfico de tendencia
fig_tendencia = go.Figure()

# Agregar los valores reales
fig_tendencia.add_trace(go.Scatter(x=data_nuevo.index, y=data_nuevo['temp'], mode='lines+markers', name='Real', line=dict(color='blue')))

# Agregar las predicciones
fig_tendencia.add_trace(go.Scatter(x=fechas_prediccion, y=y_pred_xgb_nuevo, mode='lines', name='Predicción', line=dict(color='red')))

# Actualizar el diseño del gráfico
fig_tendencia.update_layout(title='Tendencia de Predicción de Temperatura',
                             xaxis_title='Fecha y Hora',
                             yaxis_title='Temperatura (°C)',
                             hovermode="x unified")

# Mostrar la figura
fig_tendencia.show()

# Grafíco de la tendencia mensual
import pandas as pd
import plotly.graph_objects as go

# Supongamos que tienes un DataFrame 'data_nuevo' con las fechas y temperaturas
# Vamos a agrupar los datos por mes y calcular la temperatura media mensual
#monthly_mean_temperatures = data_nuevo.resample('M').mean()

# Crear el gráfico de tendencia mensual
#fig_tendencia_mensual = go.Figure()

# Agregar los valores reales mensuales
#fig_tendencia_mensual.add_trace(go.Scatter(x=monthly_mean_temperatures.index, y=monthly_mean_temperatures['temp'], mode='lines+markers', name='Real', line=dict(color='blue')))

# Agregar las predicciones (si tienes predicciones mensuales)
# Aquí asumimos que 'fechas_prediccion' contiene las fechas de las predicciones mensuales y 'y_pred_xgb_nuevo' las predicciones correspondientes
# Si no tienes predicciones mensuales, puedes omitir esta parte
# fig_tendencia_mensual.add_trace(go.Scatter(x=fechas_prediccion, y=y_pred_xgb_nuevo, mode='lines', name='Predicción', line=dict(color='red')))

# Actualizar el diseño del gráfico
#fig_tendencia_mensual.update_layout(title='Tendencia Mensual de Predicción de Temperatura',
                                    #xaxis_title='Mes',
                                    #yaxis_title='Temperatura Promedio (°C)',
                                    #hovermode="x unified")

# Mostrar la figura
#fig_tendencia_mensual.show()

# Armamos un dataframe con las predicciones
# Crear un DataFrame de las predicciones
#Crear un DataFrame con fechas y horas
fechas = data_nuevo.index
fechas_df = pd.DataFrame({'fecha': fechas})

# Hacer predicciones con el modelo entrenado
predicciones = xgb_model_nuevo.predict(X_nuevo)

# Crear un DataFrame con las predicciones
predicciones_df = pd.DataFrame({'prediccion': predicciones})

# Concatenar los DataFrames de fechas y predicciones
tabla_predicciones = pd.concat([fechas_df, predicciones_df], axis=1)

# Contar NaN por columna
nan_count = predicciones_df.isnull().sum()
print(nan_count)


# Imprimir la tabla de predicciones
print(tabla_predicciones)
print(tabla_predicciones.tail(30))

# Convertir el DataFrame a formato JSON
json_data = tabla_predicciones.to_json(orient='records')

# Imprimir el JSON en la consola
print(json_data)







